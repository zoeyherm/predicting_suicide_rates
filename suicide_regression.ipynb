{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import patsy\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 527 entries, 1 to 3129\n",
      "Data columns (total 30 columns):\n",
      "County_x                              527 non-null object\n",
      "County_code                           527 non-null float64\n",
      "rate                                  527 non-null float64\n",
      "State_x                               527 non-null object\n",
      "% Fair/Poor Health                    527 non-null int64\n",
      "% LBW                                 527 non-null float64\n",
      "% Smokers                             527 non-null int64\n",
      "% Obese                               527 non-null int64\n",
      "Food Environment Index                527 non-null float64\n",
      "% Physically Inactive                 527 non-null int64\n",
      "% Excessive Drinking                  527 non-null int64\n",
      "% driving deaths Alcohol-Impaired     527 non-null float64\n",
      "Teen Birth Rate                       527 non-null float64\n",
      "% Uninsured                           527 non-null float64\n",
      "PCP Ratio                             527 non-null float64\n",
      "Dentist Ratio                         527 non-null float64\n",
      "MHP Ratio                             527 non-null float64\n",
      "Preventable Hosp. Rate                527 non-null float64\n",
      "Graduation Rate                       527 non-null float64\n",
      "% Some College                        527 non-null int64\n",
      "% Unemployed                          527 non-null float64\n",
      "% Children in Poverty                 527 non-null float64\n",
      "Income Ratio inequality               527 non-null float64\n",
      "% Single-Parent Households            527 non-null float64\n",
      "Association Rate                      527 non-null float64\n",
      "Violent Crime Rate                    527 non-null float64\n",
      "Average Daily PM2.5                   527 non-null float64\n",
      "% Severe Housing Problems             527 non-null int64\n",
      "% Long Commute - Drives Alone         527 non-null int64\n",
      "% With Access eng 1                   527 non-null float64\n",
      "dtypes: float64(20), int64(8), object(2)\n",
      "memory usage: 127.6+ KB\n"
     ]
    }
   ],
   "source": [
    "with open('suicide1.pickle', 'rb') as read_file:\n",
    "    df = pickle.load(read_file)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>rate</td>       <th>  R-squared:         </th> <td>   0.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   32.13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Oct 2019</td> <th>  Prob (F-statistic):</th> <td>1.37e-89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:39:21</td>     <th>  Log-Likelihood:    </th> <td> -1480.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   527</td>      <th>  AIC:               </th> <td>   3015.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   500</td>      <th>  BIC:               </th> <td>   3130.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    26</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                              <td>   84.5416</td> <td>    7.721</td> <td>   10.950</td> <td> 0.000</td> <td>   69.372</td> <td>   99.711</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% Fair/Poor Health</th>                 <td>   -0.1711</td> <td>    0.130</td> <td>   -1.319</td> <td> 0.188</td> <td>   -0.426</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% LBW</th>                              <td>   -0.4291</td> <td>    0.215</td> <td>   -1.995</td> <td> 0.047</td> <td>   -0.852</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% Smokers</th>                          <td>    0.5637</td> <td>    0.111</td> <td>    5.065</td> <td> 0.000</td> <td>    0.345</td> <td>    0.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% Obese</th>                            <td>   -0.2205</td> <td>    0.072</td> <td>   -3.073</td> <td> 0.002</td> <td>   -0.361</td> <td>   -0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Food Environment Index</th>             <td>   -2.3634</td> <td>    0.394</td> <td>   -6.002</td> <td> 0.000</td> <td>   -3.137</td> <td>   -1.590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% Physically Inactive</th>              <td>   -0.0695</td> <td>    0.077</td> <td>   -0.899</td> <td> 0.369</td> <td>   -0.221</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% Excessive Drinking</th>               <td>   -0.2084</td> <td>    0.086</td> <td>   -2.432</td> <td> 0.015</td> <td>   -0.377</td> <td>   -0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% driving deaths Alcohol-Impaired </th> <td>    0.0299</td> <td>    0.028</td> <td>    1.067</td> <td> 0.286</td> <td>   -0.025</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Teen Birth Rate</th>                    <td>    0.1792</td> <td>    0.040</td> <td>    4.498</td> <td> 0.000</td> <td>    0.101</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% Uninsured</th>                        <td>   -0.2973</td> <td>    0.078</td> <td>   -3.806</td> <td> 0.000</td> <td>   -0.451</td> <td>   -0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCP Ratio</th>                          <td>    0.0014</td> <td>    0.000</td> <td>    3.079</td> <td> 0.002</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dentist Ratio</th>                      <td>   -0.0016</td> <td>    0.000</td> <td>   -3.501</td> <td> 0.001</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MHP Ratio</th>                          <td>    0.0012</td> <td>    0.001</td> <td>    1.781</td> <td> 0.076</td> <td>   -0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Preventable Hosp. Rate</th>             <td>   -0.0007</td> <td>    0.000</td> <td>   -2.796</td> <td> 0.005</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Graduation Rate</th>                    <td>   -0.0587</td> <td>    0.040</td> <td>   -1.481</td> <td> 0.139</td> <td>   -0.137</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% Some College</th>                     <td>   -0.1705</td> <td>    0.045</td> <td>   -3.753</td> <td> 0.000</td> <td>   -0.260</td> <td>   -0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% Unemployed</th>                       <td>   -0.6715</td> <td>    0.211</td> <td>   -3.185</td> <td> 0.002</td> <td>   -1.086</td> <td>   -0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% Children in Poverty</th>              <td>    0.0806</td> <td>    0.076</td> <td>    1.053</td> <td> 0.293</td> <td>   -0.070</td> <td>    0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Income Ratio inequality</th>            <td>    0.2937</td> <td>    0.460</td> <td>    0.639</td> <td> 0.523</td> <td>   -0.610</td> <td>    1.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% Single-Parent Households</th>         <td>   -0.2379</td> <td>    0.057</td> <td>   -4.143</td> <td> 0.000</td> <td>   -0.351</td> <td>   -0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Association Rate</th>                   <td>    0.1002</td> <td>    0.087</td> <td>    1.155</td> <td> 0.249</td> <td>   -0.070</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Violent Crime Rate</th>                 <td>   -0.0018</td> <td>    0.001</td> <td>   -1.445</td> <td> 0.149</td> <td>   -0.004</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Average Daily PM2.5</th>                <td>   -0.8719</td> <td>    0.115</td> <td>   -7.550</td> <td> 0.000</td> <td>   -1.099</td> <td>   -0.645</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% Severe Housing Problems</th>          <td>   -0.2261</td> <td>    0.084</td> <td>   -2.704</td> <td> 0.007</td> <td>   -0.390</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% Long Commute - Drives Alone</th>      <td>   -0.0462</td> <td>    0.024</td> <td>   -1.935</td> <td> 0.054</td> <td>   -0.093</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>% With Access eng 1</th>                <td>-4.443e-08</td> <td> 1.17e-08</td> <td>   -3.806</td> <td> 0.000</td> <td>-6.74e-08</td> <td>-2.15e-08</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>70.381</td> <th>  Durbin-Watson:     </th> <td>   1.731</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 191.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.660</td> <th>  Prob(JB):          </th> <td>3.19e-42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.638</td> <th>  Cond. No.          </th> <td>2.57e+09</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.57e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   rate   R-squared:                       0.626\n",
       "Model:                            OLS   Adj. R-squared:                  0.606\n",
       "Method:                 Least Squares   F-statistic:                     32.13\n",
       "Date:                Mon, 07 Oct 2019   Prob (F-statistic):           1.37e-89\n",
       "Time:                        18:39:21   Log-Likelihood:                -1480.4\n",
       "No. Observations:                 527   AIC:                             3015.\n",
       "Df Residuals:                     500   BIC:                             3130.\n",
       "Df Model:                          26                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================================\n",
       "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------\n",
       "const                                 84.5416      7.721     10.950      0.000      69.372      99.711\n",
       "% Fair/Poor Health                    -0.1711      0.130     -1.319      0.188      -0.426       0.084\n",
       "% LBW                                 -0.4291      0.215     -1.995      0.047      -0.852      -0.006\n",
       "% Smokers                              0.5637      0.111      5.065      0.000       0.345       0.782\n",
       "% Obese                               -0.2205      0.072     -3.073      0.002      -0.361      -0.080\n",
       "Food Environment Index                -2.3634      0.394     -6.002      0.000      -3.137      -1.590\n",
       "% Physically Inactive                 -0.0695      0.077     -0.899      0.369      -0.221       0.082\n",
       "% Excessive Drinking                  -0.2084      0.086     -2.432      0.015      -0.377      -0.040\n",
       "% driving deaths Alcohol-Impaired      0.0299      0.028      1.067      0.286      -0.025       0.085\n",
       "Teen Birth Rate                        0.1792      0.040      4.498      0.000       0.101       0.258\n",
       "% Uninsured                           -0.2973      0.078     -3.806      0.000      -0.451      -0.144\n",
       "PCP Ratio                              0.0014      0.000      3.079      0.002       0.000       0.002\n",
       "Dentist Ratio                         -0.0016      0.000     -3.501      0.001      -0.002      -0.001\n",
       "MHP Ratio                              0.0012      0.001      1.781      0.076      -0.000       0.002\n",
       "Preventable Hosp. Rate                -0.0007      0.000     -2.796      0.005      -0.001      -0.000\n",
       "Graduation Rate                       -0.0587      0.040     -1.481      0.139      -0.137       0.019\n",
       "% Some College                        -0.1705      0.045     -3.753      0.000      -0.260      -0.081\n",
       "% Unemployed                          -0.6715      0.211     -3.185      0.002      -1.086      -0.257\n",
       "% Children in Poverty                  0.0806      0.076      1.053      0.293      -0.070       0.231\n",
       "Income Ratio inequality                0.2937      0.460      0.639      0.523      -0.610       1.197\n",
       "% Single-Parent Households            -0.2379      0.057     -4.143      0.000      -0.351      -0.125\n",
       "Association Rate                       0.1002      0.087      1.155      0.249      -0.070       0.271\n",
       "Violent Crime Rate                    -0.0018      0.001     -1.445      0.149      -0.004       0.001\n",
       "Average Daily PM2.5                   -0.8719      0.115     -7.550      0.000      -1.099      -0.645\n",
       "% Severe Housing Problems             -0.2261      0.084     -2.704      0.007      -0.390      -0.062\n",
       "% Long Commute - Drives Alone         -0.0462      0.024     -1.935      0.054      -0.093       0.001\n",
       "% With Access eng 1                -4.443e-08   1.17e-08     -3.806      0.000   -6.74e-08   -2.15e-08\n",
       "==============================================================================\n",
       "Omnibus:                       70.381   Durbin-Watson:                   1.731\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              191.100\n",
       "Skew:                           0.660   Prob(JB):                     3.19e-42\n",
       "Kurtosis:                       5.638   Cond. No.                     2.57e+09\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.57e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLS without patsy\n",
    "\n",
    "objectdroplist = ['State_x', 'County_code', 'County_x']\n",
    "\n",
    "X = df.drop(columns=[\"rate\"] + objectdroplist).astype(float)\n",
    "y = df.loc[:,\"rate\"].astype(float)\n",
    "\n",
    "model = sm.OLS(y, sm.add_constant(X), data = df)\n",
    "results = model.fit() \n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=.2, random_state=5)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=.2, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression train R^2: 0.635\n",
      "Linear Regression val R^2: 0.539\n",
      "Linear Regression test R^2: 0.527\n",
      "Ridge Regression train R^2: 0.592\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=StandardScaler(copy=True, with_mean=True, with_std=True).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-f65559f6261e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Linear Regression test R^2: {lm.score(X_test, y_test):.3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Ridge Regression train R^2: {lm_reg.score(X_train_scaled, y_train):.3f}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Ridge Regression val R^2: {lm_reg.score(X_val_scaled, y_val):.3f}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Ridge Regression test R^2: {lm_reg.score(X_test_scaled, y_test):.3f}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_check_reg_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;31m# XXX: Remove the check in 0.23\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_reg_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coef_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m    206\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    512\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=StandardScaler(copy=True, with_mean=True, with_std=True).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "scaler = StandardScaler()\n",
    "lm_reg = Ridge(alpha=100)\n",
    "\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "X_val_scaled = scaler.fit(X_val.values)\n",
    "X_test_scaled = scaler.fit(X_test.values)\n",
    "\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "lm_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f'Linear Regression train R^2: {lm.score(X_train, y_train):.3f}')\n",
    "print(f'Linear Regression val R^2: {lm.score(X_val, y_val):.3f}')\n",
    "print(f'Linear Regression test R^2: {lm.score(X_test, y_test):.3f}')\n",
    "print(f'Ridge Regression train R^2: {lm_reg.score(X_train_scaled, y_train):.3f}\\n')\n",
    "print(f'Ridge Regression val R^2: {lm_reg.score(X_val_scaled, y_val):.3f}\\n')\n",
    "print(f'Ridge Regression test R^2: {lm_reg.score(X_test_scaled, y_test):.3f}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param_grid = {'alpha': np.linspace(0.0, 1.0, 100)} #\n",
    "\n",
    "my_model = Ridge()\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "my_grid_search_ridge = GridSearchCV(my_model, param_grid, cv = 5, n_jobs = 1)\n",
    "my_grid_search_ridge.fit(X_train_scaled, y_train)\n",
    "my_grid_search_ridge.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([  1,   3,   4,   5,   7,   8,  12,  13,  14,  16,\\n            ...\\n            508, 510, 512, 514, 516, 517, 518, 521, 524, 525],\\n           dtype='int64', length=421)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-e5f099293c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2986\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 raise KeyError(\n\u001b[1;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1177\u001b[0;31m                         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m                     )\n\u001b[1;32m   1179\u001b[0m                 )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([  1,   3,   4,   5,   7,   8,  12,  13,  14,  16,\\n            ...\\n            508, 510, 512, 514, 516, 517, 518, 521, 524, 525],\\n           dtype='int64', length=421)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "#run the CV\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "cv_lm_r2s, cv_lm_reg_r2s = [], [] #collect the validation results for both models\n",
    "\n",
    "for train_ind, val_ind in kf.split(X,y):\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind] \n",
    "    \n",
    "    #simple linear regression\n",
    "    lm = LinearRegression()\n",
    "#    lm_reg = Ridge(alpha=1)\n",
    "\n",
    "    lm.fit(X_train, y_train)\n",
    "    cv_lm_r2s.append(lm.score(X_val, y_val))\n",
    "    \n",
    "    #ridge with feature scaling\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train_scaled = scaler.fit_transform(X_train)\n",
    "#     X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "#     lm_reg.fit(X_train_scaled, y_train)\n",
    "#     cv_lm_reg_r2s.append(lm_reg.score(X_val_scaled, y_val))\n",
    "\n",
    "print('Simple regression scores: ', cv_lm_r2s)\n",
    "# print('Ridge scores: ', cv_lm_reg_r2s, '\\n')\n",
    "\n",
    "# print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')\n",
    "# print(f'Ridge mean cv r^2: {np.mean(cv_lm_reg_r2s):.3f} +- {np.std(cv_lm_reg_r2s):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
